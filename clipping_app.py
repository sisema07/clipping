import streamlit as st
import feedparser
import requests
from datetime import datetime, timedelta, timezone, time as dt_time

# --- CONFIGURA√á√ÉO ---
st.set_page_config(page_title="Clipping Alerts", page_icon="üîó", layout="wide")
st.title("üîó Formatador de Google Alerts")
st.markdown("Transforma seus RSS do Google Alerts em uma lista √∫nica e limpa (08:30 √†s 08:30).")

# ==============================================================================
# √ÅREA DE CONFIGURA√á√ÉO DOS LINKS (COLE SEUS LINKS DO GOOGLE ALERTS AQUI)
# ==============================================================================

# Lista 1: Links dos Alertas do SISEMA (Semad, IEF, Feam, Igam...)
# Cole cada link RSS entre aspas, separado por v√≠rgula.
URLS_ALERTS_SISEMA = [
    "https://www.google.com.br/alerts/feeds/06474796398566785113/8556040124559167503",
    "https://www.google.com.br/alerts/feeds/06474796398566785113/3256954388664724591",
    "https://www.google.com.br/alerts/feeds/06474796398566785113/8177748629976302199",
    "https://www.google.com.br/alerts/feeds/06474796398566785113/779453071302735537"
]

# Lista 2: Links dos Alertas GERAIS (Relevantes, Curiosidades...)
URLS_ALERTS_GERAL = [
    "https://www.google.com.br/alerts/feeds/06474796398566785113/13915059247713257237"
]

# ==============================================================================

def resolver_link_final(url_google):
    """Transforma o link redirecionado do Google no link real do site"""
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        # O Google Alerts usa links do tipo google.com/url?q=...
        # Precisamos extrair o 'q' ou seguir o redirect.
        if "url?q=" in url_google:
            # Tentativa r√°pida de extra√ß√£o via texto (mais r√°pido que requisi√ß√£o)
            inicio = url_google.find("url?q=") + 6
            fim = url_google.find("&ct=")
            if fim != -1:
                return url_google[inicio:fim]
        
        # Se n√£o der certo extrair, faz a requisi√ß√£o
        r = requests.head(url_google, allow_redirects=True, timeout=5, headers=headers)
        if r.status_code == 200: return r.url
        r = requests.get(url_google, allow_redirects=True, timeout=5, headers=headers)
        return r.url
    except:
        return url_google

def limpar_nome_veiculo(nome_cru, titulo_materia):
    # Tenta pegar do t√≠tulo (Padr√£o: T√≠tulo - Ve√≠culo)
    if " - " in titulo_materia:
        possivel_nome = titulo_materia.rsplit(" - ", 1)[1].strip()
        if len(possivel_nome) < 40: nome_cru = possivel_nome

    nome = nome_cru.replace("www.", "").replace(".com.br", "").replace(".com", "").replace(".gov", "")
    nome = nome.replace("-", " ").replace("_", " ")
    
    mapa = {
        "gazetadevarginha": "Gazeta de Varginha", "diariodoaco": "Di√°rio do A√ßo",
        "em": "Estado de Minas", "otempo": "O Tempo", "hojeemdia": "Hoje em Dia",
        "folha": "Folha de S.Paulo", "agenciaminas": "Ag√™ncia Minas",
        "g1": "Portal G1", "uol": "Portal UOL", "r7": "Portal R7", "youtube": "YouTube",
        "oeco": "O Eco", "conexaoplaneta": "Conex√£o Planeta"
    }
    
    nome_lower = nome.lower()
    for k, v in mapa.items():
        if k in nome_lower: return v
    return nome.title()

def converter_para_brt(struct_time_utc):
    dt_utc = datetime(*struct_time_utc[:6], tzinfo=timezone.utc)
    return (dt_utc - timedelta(hours=3)).replace(tzinfo=None)

def processar_feeds(lista_urls, data_referencia):
    # Define a janela 08:30 (Ontem) at√© 08:30 (Hoje)
    fim_janela = datetime.combine(data_referencia, dt_time(8, 30))
    inicio_janela = fim_janela - timedelta(days=1)
    
    resultados = {}
    links_vistos = set()
    
    progresso_total = len(lista_urls)
    barra = st.progress(0)
    msg = st.empty()
    
    for i, url in enumerate(lista_urls):
        if "COLE_O_LINK" in url: continue # Pula placeholders vazios
        
        msg.text(f"Lendo Alerta {i+1}...")
        barra.progress((i)/progresso_total)
        
        feed = feedparser.parse(url)
        
        for entry in feed.entries:
            # 1. Filtro de Hor√°rio
            if hasattr(entry, 'published_parsed'):
                try:
                    pub_dt = converter_para_brt(entry.published_parsed)
                    if not (inicio_janela <= pub_dt <= fim_janela):
                        continue
                except: continue
            
            # 2. Dados
            titulo = entry.title
            
            # Limpeza HTML que √†s vezes vem no t√≠tulo do Alerts
            titulo = titulo.replace("<b>", "").replace("</b>", "").replace("&quot;", '"')
            
            # Limpeza Ve√≠culo
            if " - " in titulo: 
                titulo_limpo = titulo.rsplit(" - ", 1)[0]
            else: 
                titulo_limpo = titulo
            
            # Deduplica√ß√£o
            chave = titulo_limpo.lower()
            if chave not in links_vistos:
                links_vistos.add(chave)
                
                v_raw = entry.source.title if 'source' in entry else "Fonte Desconhecida"
                veiculo = limpar_nome_veiculo(v_raw, entry.title)
                link_real = resolver_link_final(entry.link)
                
                if veiculo not in resultados: resultados[veiculo] = []
                resultados[veiculo].append({'titulo': titulo_limpo, 'link': link_real})
    
    barra.empty()
    msg.empty()
    return resultados

# --- INTERFACE ---

st.info("Este sistema processa os links RSS do seu Google Alerts, filtra pelo hor√°rio (08:30 a 08:30) e formata a lista.")
data = st.date_input("Data de Refer√™ncia:", format="DD/MM/YYYY")

if st.button("üöÄ Processar Alertas", type="primary"):
    
    # Valida√ß√£o simples
    if "COLE_O_LINK" in URLS_ALERTS_SISEMA[0]:
        st.error("‚ö†Ô∏è Voc√™ precisa colar os links RSS do Google Alerts no c√≥digo (arquivo .py) antes de rodar!")
    else:
        d_sisema = processar_feeds(URLS_ALERTS_SISEMA, data)
        d_geral = processar_feeds(URLS_ALERTS_GERAL, data)
        
        # --- MONTAGEM DO TEXTO ---
        ontem = data - timedelta(days=1)
        txt = f"CLIPPING DI√ÅRIO - {data.strftime('%d/%m/%Y')}\n"
        txt += f"Janela: {ontem.strftime('%d/%m')} (08:30) a {data.strftime('%d/%m')} (08:30)\n\n"
        
        def fmt(dados, tit):
            t = f"=== {tit} ===\n"
            if not dados: return t + "Nenhuma mat√©ria encontrada neste per√≠odo.\n\n"
            for v in sorted(dados.keys()):
                t += f"{v}\n"
                for n in dados[v]:
                    t += f"{n['titulo']}\n{n['link']}\n"
                t += "\n"
            return t + "\n"

        txt += fmt(d_sisema, "MAT√âRIAS QUE CITAM O SISEMA")
        txt += "----------------------------------------\n\n"
        txt += fmt(d_geral, "MAT√âRIAS AMBIENTAIS RELEVANTES")
        
        st.success("Lista Gerada com a precis√£o do Google Alerts!")
        st.text_area("Copie aqui:", txt, height=600)
        
        # √Årea de confer√™ncia
        st.markdown("---")
        c1, c2 = st.columns(2)
        def conf(dados, tit):
            st.markdown(f"##### {tit}")
            if not dados: st.caption("Vazio")
            for v in sorted(dados.keys()):
                st.markdown(f"**{v}**")
                for n in dados[v]: st.markdown(f"‚Ä¢ [{n['titulo']}]({n['link']})")
        
        with c1: conf(d_sisema, "SISEMA")
        with c2: conf(d_geral, "GERAL")
